{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Data extraction from h5 to csv\n",
    "### 2.1 Particularity of h5 data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is in .h5 format. This is a specific format, like python libraries, to save and structure file with huge amount of data.   \n",
    "As there are specific functions for this format, we choose to transform it in .csv format to retrieve all the functions we already know (read.csv(), fwrite(), fread()).    \n",
    "\n",
    "However, the initial dataset (in .h5) correspond to a 4-dimensional-array (946_ID*7_canals*40_segments*500_observations).   \n",
    "To transform it in a .csv format, we need to flatten dimensions from 4-dim to 2-dim. To do that, using three for-loops and for each segment (and its 500 observations), we save the segment number, the canal number, the ID number and its corresponding 500 observations.      \n",
    "\n",
    "At the end, we obtain 946*7*40 = **264 880 rows**.   \n",
    "Hence, for each row, the key is (ID, CANAL, SEGMENT) and the attributes are the 500 observations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Due to the size of the source files, we have run these functions on different instances locally. Here, the code is therefore not launched in html. The final results of the functions have been uploaded to the cloud in csv format so that everyone can retrieve them and follow the code of steps 3, 4 and 5.* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Functions to convert h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(magrittr)\n",
    "library(data.table)\n",
    "#install.packages(\"BiocManager\")\n",
    "library(BiocManager)\n",
    "#BiocManager::install(c(\"rhdf5\"))\n",
    "library(rhdf5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in H5Fopen(\"X_train_new.h5\"): HDF5. File accessibilty. Unable to open file.\n",
     "output_type": "error",
     "traceback": [
      "Error in H5Fopen(\"X_train_new.h5\"): HDF5. File accessibilty. Unable to open file.\nTraceback:\n",
      "1. H5Fopen(\"X_train_new.h5\")"
     ]
    }
   ],
   "source": [
    "x_train=H5Fopen(\"X_train_new.h5\")\n",
    "View(x_train$features[,,1,1]) #(500, 7, 40, 946)\n",
    "x_train.new <- aperm(x_train$features, c(4,2,1,3)) #(946, 7, 500, 40)\n",
    "View(x_train.new[946,1,1,1]) #(946, 7, 500, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A data.table: 1 × 3</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>V1</th><th scope=col>V2</th><th scope=col>V3</th></tr>\n",
       "\t<tr><th scope=col>&lt;lgl&gt;</th><th scope=col>&lt;lgl&gt;</th><th scope=col>&lt;lgl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>NA</td><td>NA</td><td>NA</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.table: 1 × 3\n",
       "\\begin{tabular}{lll}\n",
       " V1 & V2 & V3\\\\\n",
       " <lgl> & <lgl> & <lgl>\\\\\n",
       "\\hline\n",
       "\t NA & NA & NA\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.table: 1 × 3\n",
       "\n",
       "| V1 &lt;lgl&gt; | V2 &lt;lgl&gt; | V3 &lt;lgl&gt; |\n",
       "|---|---|---|\n",
       "| NA | NA | NA |\n",
       "\n"
      ],
      "text/plain": [
       "  V1 V2 V3\n",
       "1 NA NA NA"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_aux <- data.table(matrix(ncol=3, nrow= 1))\n",
    "df_aux[,1] = 1\n",
    "df_aux[,2] = 1\n",
    "df_aux[,3] = 1\n",
    "df_aux = cbind(df_aux, t(x_train.new[1,1,,1]))\n",
    "\n",
    "df <- df_aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c=0\n",
    "for (i in 1:946) {\n",
    "  for(j in 1:7) {\n",
    "    for(k in 1:40) {\n",
    "       df_aux <- data.table(matrix(ncol=3, nrow= 1))\n",
    "       df_aux[,1] = i\n",
    "       df_aux[,2] = j\n",
    "       df_aux[,3] = k\n",
    "       \n",
    "       df_aux = cbind(df_aux, t(x_train.new[i,j,,k]))\n",
    "       ###valeurs \n",
    "       df = rbind(df, df_aux)\n",
    "       \n",
    "       c=c+1\n",
    "       \n",
    "       print(c)\n",
    "    }\n",
    "  }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fwrite(df,\"X_train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Same steps for X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test=H5Fopen(\"X_test_new.h5\")\n",
    "View(x_test$features[,,1,1]) #(500, 7, 40, 946)\n",
    "x_test.new <- aperm(x_test$features, c(4,2,1,3)) #(946, 7, 500, 40)\n",
    "View(x_test[946,1,1,1]) #(946, 7, 500, 40)\n",
    "df_aux <- data.table(matrix(ncol=3, nrow= 1))\n",
    "df_aux[,1] = 1\n",
    "df_aux[,2] = 1\n",
    "df_aux[,3] = 1\n",
    "df_aux = cbind(df_aux, t(x_train.new[1,1,,1]))\n",
    "\n",
    "df <- df_aux\n",
    "c=0\n",
    "for (i in 1:946) {\n",
    "  for(j in 1:7) {\n",
    "    for(k in 1:40) {\n",
    "       df_aux <- data.table(matrix(ncol=3, nrow= 1))\n",
    "       df_aux[,1] = i\n",
    "       df_aux[,2] = j\n",
    "       df_aux[,3] = k\n",
    "       \n",
    "       df_aux = cbind(df_aux, t(x_train.new[i,j,,k]))\n",
    "       ###valeurs \n",
    "       df = rbind(df, df_aux)\n",
    "       \n",
    "       c=c+1\n",
    "       \n",
    "       print(c)\n",
    "    }\n",
    "  }\n",
    "fwrite(df,\"X_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Verify results and clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.1 Verify for X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=fread(\"X_train.csv\")\n",
    "X_train<-X_train[-1,]\n",
    "X_train[1,]\n",
    "\n",
    "setnames(X_train, \"V1\", \"Idligne\")\n",
    "setnames(X_train, \"V1\", \"Id\")\n",
    "setnames(X_train, \"V2\", \"Channels\")\n",
    "setnames(X_train, \"V3\", \"Segments\")\n",
    "\n",
    "\n",
    "x_train_h5=H5Fopen(\"X_train_new.h5\")\n",
    "x_train_h5 <- aperm(x_train_h5$features, c(4,2,1,3)) #(946, 7, 500, 40)\n",
    "\n",
    "\n",
    "h5closeAll()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "First ID check, 1st channel, 1 st Segment\n",
    "\n",
    "(X_train[1,])\n",
    "View(x_train_h5[1,1,,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ok"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1s ID check, 1st channel, 2 sd Segment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train[3,])\n",
    "View(x_train_h5[1,1,,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok ! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There should be 264 880 obv (946*7*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train[X_train$Channel==1 & X_train$Segments==1 & X_train$Id==1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=> First duplicate at line 9391 - 1 (we removed 1 line at the strat)\n",
    "We remove the first 1:9390 lines (9389 obs which makes 264880)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train<-X_train[-c(1:9389),]\n",
    "X_train<-X_train[,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.2 Verify for X_test.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=fread(\"X_test_new.csv\")\n",
    "X_test[1:4,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_test<-X_test[-c(1,2),]#Remove first and second line\n",
    "X_test[1,]\n",
    "setnames(X_test, \"V1\", \"Id\")\n",
    "setnames(X_test, \"V2\", \"Channels\")\n",
    "setnames(X_test, \"V3\", \"Segments\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_test_h5=H5Fopen(\"X_test_new.h5\")\n",
    "\n",
    "\n",
    "x_test_h5 <- aperm(x_test_h5$features, c(4,2,1,3)) #(946, 7, 500, 40)\n",
    "\n",
    "\n",
    "h5closeAll()\n",
    "\n",
    "\n",
    "h5ls(\"X_train_new.h5\", all=TRUE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "First ID check, 1st channel, 1 st Segment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_test[1,])\n",
    "View(x_test_h5[1,1,,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ok ! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1s ID check, 2sn channel, 2 Segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_test[X_test$Channel==2 & X_test$Segments==2 & X_test$Id==1])\n",
    "View(x_test_h5[1,2,,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "but OK ! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.3 Export our new dataset cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fwrite(X_test,\"X_test_clean\")\n",
    "fwrite(X_train,\"X_train_clean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have uploaded our csv cleaned in aws cloud :    \n",
    "X_test(\"https://u2bigdataprojectpredictfrombraina-donotdelete-pr-keui4jukxng1lb.s3.eu.cloud-object-storage.appdomain.cloud/X_test.csv\")     \n",
    "Y_train(\"https://u2bigdataprojectpredictfrombraina-donotdelete-pr-keui4jukxng1lb.s3.eu.cloud-object-storage.appdomain.cloud/y_train.csv\")    \n",
    "X_train(\"https://u2bigdataprojectpredictfrombraina-donotdelete-pr-keui4jukxng1lb.s3.eu.cloud-object-storage.appdomain.cloud/X_train.csv\")    \n",
    "\n",
    "We can now pass to the EDA & Pre-processing ! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
